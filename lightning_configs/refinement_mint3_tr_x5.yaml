seed_everything: 42

# ---------------------------- TRAINER -------------------------------------------
trainer:
  default_root_dir: /data0/jacklishufan/physics_sim-v3-5dataset-v7-2-baseline-newdata-v2/

  precision: 32
  # accumulate_grad_batches: 8
  val_check_interval: 200

  devices: 1
  num_nodes: 1
  accelerator: gpu
  strategy:
    class_path: lightning.pytorch.strategies.DDPStrategy
    init_args:
      find_unused_parameters: true

  min_epochs: 1
  max_epochs: 5
  enable_progress_bar: true

  sync_batchnorm: True
  enable_checkpointing: True
  num_sanity_val_steps: 4

  # debugging
  fast_dev_run: false

  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      project: 'physics_sim'
      save_dir: ${trainer.default_root_dir}/test
      name: test
      
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"

    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "${trainer.default_root_dir}/test/checkpoints"
        monitor: "val/loss" # name of the logged metric which determines when model is improving
        mode: "min"
        save_top_k: 1 # save k best models (determined by above metric)
        save_last: True # additionaly always save model from last epoch
        verbose: False
        filename: "epoch_{epoch:03d}"
        auto_insert_metric_name: False

    # - class_path: lightning.pytorch.callbacks.EarlyStopping
    #   init_args:
    #     monitor: "val/loss"
    #     mode: "min"
    #     patience: 10 # how many validation epochs of not improving until training stops
    #     min_delta: 0. # minimum change in the monitored metric needed to qualify as an improvement

    - class_path: lightning.pytorch.callbacks.RichModelSummary
      init_args:
        max_depth: -1

    - class_path: lightning.pytorch.callbacks.TQDMProgressBar

# ---------------------------- MODEL -------------------------------------------
model:
  accumulate_grad_batches: 16
  # normalization_path: ${data.normalization_stats}/normalization_stats.json
  context_frames: 4
  grounding_frames: ${data.grounding_frames}
  # load_path: /data1/jacklishufan/convenext.safetensors
  model_config:
    blocks_at_neck: 1
    blocks_per_stage: 2
    dim_in: 32
    dim_out: 4
    gradient_checkpointing: false
    #init_features: 42
    init_features: 42
    n_spatial_dims: 2
    spatial_resolution: [128, 384]
    stages: 4 
    predict_delta: false
    delta_t_project: false # baseline
  pretrained_path: null
  loss_type: "mse"
  lr: 5e-3
  beta_1: 0.9
  beta_2: 0.95
  warmup_epochs: 0.05
  max_epochs: 5
  warmup_start_lr: 0
  eta_min: 0

# ---------------------------- DATA -------------------------------------------
data:
  context_frames: ${model.context_frames}
  # max_start_idx: 5 # [0,1,2,3 | 4]
  max_start_idx: -1 #-1 only learn 1 frame
  baseline_format: true
  root_dir: /data1/jacklishufan/data/the_well/cosmos-refinement/turbulent_radiative_layer_2D/
  # val_dir: /data0/jacklishufan/cosmos-refinement/tr2d/
  val_dir: /data0/tungnd/the_well/cosmos-refinement/turbulent_radiative_layer_2D/

  grounding_frames: []
  normalization_stats: /data0/arshkon/data/the_well/normalized/turbulent_radiative_layer_2D/
  total_frames: 13
  batch_size: 4
  num_workers: 4
  pin_memory: False
